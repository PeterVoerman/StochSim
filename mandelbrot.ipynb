{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "import scipy.optimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_AREA = 1.506484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandelbrot(xmin, xmax, ymin, ymax, xiter, yiter, limit):\n",
    "    \"\"\" \n",
    "    Creates a list of pixel values that can be used to plot the mandelbrot set\n",
    "    \"\"\"\n",
    "    a_step = 0\n",
    "\n",
    "    pixel_list = np.ndarray((xiter + 2, yiter + 2))\n",
    "\n",
    "    for a in np.linspace(xmin, xmax, xiter):\n",
    "        a_step += 1\n",
    "        b_step = 0\n",
    "        for b in np.linspace(ymin, ymax, yiter):\n",
    "            b_step += 1\n",
    "            z_0 = complex(a, b)\n",
    "            z = z_0\n",
    "            counter = 0\n",
    "\n",
    "            while abs(z) < 2 and counter < limit:\n",
    "                z = z ** 2 + z_0\n",
    "                counter += 1\n",
    "                \n",
    "            pixel_list[b_step][a_step] = counter\n",
    "    \n",
    "\n",
    "    return pixel_list\n",
    "\n",
    "xmin = -2\n",
    "xmax = 0.5\n",
    "ymin = -2\n",
    "ymax = 2\n",
    "xiter = 2000\n",
    "yiter = 2000\n",
    "limit = 250\n",
    "\n",
    "pixel_list = mandelbrot(xmin, xmax, ymin, ymax, xiter, yiter, limit)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.figure(figsize = (15, 15))\n",
    "plt.imshow(pixel_list, cmap='RdBu')\n",
    "plt.title(\"The Mandelbrot set\")\n",
    "plt.xticks(ticks=range(0, 2001, 400), labels=np.linspace(-2, 0.5, 6))\n",
    "plt.yticks(ticks=range(0, 2001, 500), labels=np.linspace(2, -2, 5))\n",
    "plt.xlabel(\"Real axis\")\n",
    "plt.ylabel(\"Imaginary axis\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = -2\n",
    "xmax = 0.5\n",
    "ymin = -2\n",
    "ymax = 2\n",
    "xiter = 2000\n",
    "yiter = 2000\n",
    "limit = 250\n",
    "\n",
    "pixel_list = mandelbrot(xmin, xmax, ymin, ymax, xiter, yiter, limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(pixel_list, cmap='RdBu')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_converge(z_0, treshold=2, max_iterations=25):\n",
    "    \"\"\"\n",
    "    Checks if the complex number z_0 converges within the max_iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    z = z_0\n",
    "    counter = 0\n",
    "    while True:\n",
    "        z = z ** 2 + z_0\n",
    "        counter += 1\n",
    "\n",
    "        if abs(z) > 2:\n",
    "            return False\n",
    "        if counter > max_iterations:\n",
    "            return True\n",
    "\n",
    "def determine_area(i = 25, s=10000, xmin=-2, xmax=1, ymin=-2, ymax=2, sample_method=\"pure\"):\n",
    "    \"\"\"\n",
    "    Determine the area of the mandelbrot set.\n",
    "\n",
    "    Parameters:\n",
    "    i: int, Max number of iterations\n",
    "    s: int, The number of sample points.\n",
    "    sample_method: string, options are:\n",
    "        'pure': pure random sampling,\n",
    "        'hypercube': hypercube sampling,\n",
    "        'orthogonal': orthogonal sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    bounding_box_area = (xmax - xmin) * (ymax - ymin)\n",
    "\n",
    "    if sample_method == \"pure\":\n",
    "        Z = generate_sample_points_pure_random(s, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n",
    "    elif sample_method == \"hypercube\":\n",
    "        Z = generate_sample_points_hypercube(s, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n",
    "    elif sample_method == \"orthogonal\":\n",
    "        Z = generate_sample_points_orthogonal(s, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n",
    "\n",
    "    Z0 = Z\n",
    "\n",
    "    N = np.zeros(Z.shape)\n",
    "\n",
    "    for _ in range(i):\n",
    "        Z = np.where(abs(Z) < 2, Z ** 2 + Z0, 100)\n",
    "\n",
    "    N[Z != 100] = 1\n",
    "\n",
    "    n_good_points = sum(N)\n",
    "    \n",
    "    return bounding_box_area * (n_good_points / s)\n",
    "\n",
    "def plot_i_s_contour(i_list, s_list, log=False):\n",
    "    \"\"\"\n",
    "    Plots the difference between the expected and calculated area for different values for i and s. \n",
    "    i is the maximum number of iterations and s is the number of samples. \n",
    "    \"\"\"\n",
    "\n",
    "    total_evaluations = len(i_list) * len(s_list)\n",
    "    n_evaluations = 0\n",
    "\n",
    "    expected_area = 1.506484\n",
    "\n",
    "    data = []\n",
    "    for i in i_list:\n",
    "\n",
    "        results = []\n",
    "        for s in s_list:\n",
    "            results.append(determine_area(i=i, s=s) - expected_area)\n",
    "            n_evaluations += 1\n",
    "\n",
    "            if log and n_evaluations % 10 == 0:\n",
    "                print(f\"Progress: {n_evaluations/total_evaluations * 100:0f}%\", end=\"\\r\")\n",
    "        \n",
    "        data.append(results)\n",
    "\n",
    "    contour = plt.contourf(s_list, i_list, data, 10, cmap=\"PuBuGn_r\")\n",
    "    \n",
    "    colorbar = plt.colorbar(contour)\n",
    "    colorbar.set_label(\"Difference between expected area\")\n",
    "\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Max iterations\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_i_s_variance(i_list, s_list, nruns=10, log=False):\n",
    "    \"\"\"\n",
    "    Plots the variance of the difference between the expected and calculated area for different values for i and s. \n",
    "    i is the maximum number of iterations and s is the number of samples. \n",
    "    \"\"\"\n",
    "    \n",
    "    total_evaluations = len(i_list) * len(s_list) * nruns\n",
    "    n_evaluations = 0\n",
    "\n",
    "    expected_area = 1.506484\n",
    "\n",
    "    data = []\n",
    "    for i in i_list:\n",
    "\n",
    "        results = []\n",
    "        for s in s_list:\n",
    "\n",
    "            run_results = []\n",
    "            for run in range(nruns):\n",
    "                run_results.append(determine_area(i=i, s=s))\n",
    "                n_evaluations += 1\n",
    "\n",
    "                if log and n_evaluations % 10 == 0:\n",
    "                    print(f\"Progress: {n_evaluations/total_evaluations * 100:1f}%\", end=\"\\r\")\n",
    "\n",
    "            results.append(np.var(run_results))\n",
    "        \n",
    "        data.append(results)\n",
    "\n",
    "    contour = plt.contourf(s_list, i_list, data, 10, cmap=\"PuBuGn_r\")\n",
    "    \n",
    "    colorbar = plt.colorbar(contour)\n",
    "    colorbar.set_label(\"Variance in area\")\n",
    "\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Max iterations\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "def generate_sample_points_pure_random(s=10000, xmin=-2, xmax=1, ymin=-2, ymax=2):\n",
    "    \n",
    "    X = rand.rand(s) * (xmax - xmin) + xmin\n",
    "    Y = rand.rand(s) * (ymax - ymin) + ymin\n",
    "\n",
    "    return X + Y * 1j\n",
    "\n",
    "def generate_sample_points_hypercube(s=10000, xmin=-2, xmax=1, ymin=-2, ymax=2):\n",
    "    sampler = stats.qmc.LatinHypercube(2)\n",
    "    points = sampler.random(s)\n",
    "\n",
    "    l_bounds = [xmin, ymin]\n",
    "    u_bounds = [xmax, ymax]\n",
    "\n",
    "    points = stats.qmc.scale(points, l_bounds, u_bounds)\n",
    "\n",
    "    return points[:,0] + points[:,1] * 1j\n",
    "\n",
    "def generate_sample_points_orthogonal(s=10000, xmin=-2, xmax=1, ymin=-2, ymax=2):\n",
    "    \n",
    "    # Calculate the number of major cells. This has to be an integer\n",
    "    n_major_cells = int(np.sqrt(s))\n",
    "    n_samples = n_major_cells * n_major_cells\n",
    "\n",
    "    shape = (n_major_cells, n_major_cells)\n",
    "    xlist = np.zeros(shape)\n",
    "    ylist = np.zeros(shape)\n",
    "    \n",
    "    m = 0\n",
    "    for i in range(n_major_cells):\n",
    "        for j in range(n_major_cells):\n",
    "\n",
    "            xlist[i][j] = m\n",
    "            ylist[i][j] = m\n",
    "\n",
    "            m += 1\n",
    "\n",
    "    # Shuffle each row of the x and y lists\n",
    "    for i in range(n_major_cells):\n",
    "        np.random.shuffle(xlist[i])\n",
    "        np.random.shuffle(ylist[i]) \n",
    "    \n",
    "    # Transpose y since the ylist should have major rows instead of major columns\n",
    "    ylist = np.transpose(ylist)\n",
    "    \n",
    "    # Create a 1D array from the 2D array\n",
    "    xlist = np.ndarray.flatten(xlist)\n",
    "    ylist = np.ndarray.flatten(ylist)\n",
    "\n",
    "    # Calculate the width and height of each column and row\n",
    "    xscale = (xmax - xmin) / n_samples\n",
    "    yscale = (ymax - ymin) / n_samples\n",
    "\n",
    "    # Calculate the points within the minor rows and columns\n",
    "    X = xmin + xscale * (xlist + rand.rand(n_samples))\n",
    "    Y = ymin + yscale * (ylist + rand.rand(n_samples))\n",
    "\n",
    "    return X + Y * 1j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "i_list = np.logspace(0, 3, 3, dtype=int)\n",
    "s_list = np.logspace(1, 5, 3, dtype=int)\n",
    "plot_i_s_contour(i_list, s_list, log=True)\n",
    "plot_i_s_variance(i_list, s_list, nruns=3, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc i errors\n",
    "for i in [1, 10, 100, 1000, 10000, 10000]:\n",
    "    print(f\"{i}: {calc_error(i, 1000000):e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc s errors\n",
    "for s in [1, 10, 100, 1000, 10000, 100000]:\n",
    "\n",
    "    # At low s values the error will have a high variance, therefore we sample \n",
    "    # the error multiple times. There is also a error in the i value, which is \n",
    "    # substracted from the calculated error.\n",
    "    errors = []\n",
    "    for _ in range(100):\n",
    "        errors.append(abs(calc_error(1000, s)) - 0.0042440000000001366)\n",
    "\n",
    "    print(f\"{s}: {sum(errors) / len(errors):e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i error\n",
    "\n",
    "|i     |error                |\n",
    "|------|---------------------|\n",
    "|1     |8.598812000000002e0  |\n",
    "|10    |5.164399999999998e-1 |\n",
    "|100   |3.481999999999963e-2 |\n",
    "|1000  |4.2440000000001366e-3|\n",
    "|10000 |5.24000000000191e-4  |\n",
    "\n",
    "These errors were computed with s=1000000. It is assumed that these are enough samples that the error over s is negligible\n",
    "\n",
    "### s error\n",
    "\n",
    "|s     |error       |\n",
    "|------|------------|\n",
    "|1     |2.400943e+0 |\n",
    "|10    |1.011442e+0 |\n",
    "|100   |2.949779e-1 |\n",
    "|1000  |1.028386e-1 |\n",
    "|10000 |2.946552e-2 |\n",
    "|100000|6.576960e-3 |\n",
    "\n",
    "These errors were computed with i=1000. The error over i is substracted from these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "i_values = [1, 10, 100, 1000, 10000]\n",
    "i_errors = [8.598812000000002e0, 5.164399999999998e-1, 3.481999999999963e-2, 4.2440000000001366e-3, 5.24000000000191e-4]\n",
    "\n",
    "s_values = [1, 10, 100, 1000, 10000, 100000]\n",
    "s_errors = [2.400943e+0, 1.011442e+0, 2.949779e-1, 1.028386e-1, 2.946552e-2, 6.576960e-3]\n",
    "\n",
    "def linear_function(x, a=1, b=1):\n",
    "    return a * x + b\n",
    "    \n",
    "def exponential_function(x, a=1, c=1):\n",
    "    return c * x ** a\n",
    "\n",
    "def inverse_exponential_function(y, a=1, c=1):\n",
    "    \"\"\"\n",
    "    Returns the inverse of the exponential function: y = cx^a.\n",
    "    \"\"\"\n",
    "\n",
    "    return (y / c) ** (1/a)\n",
    "\n",
    "def calc_error_fit(values, errors):\n",
    "    \"\"\"\n",
    "    This function finds the fit parameters a and c for the function y = cx ^ a. \n",
    "    It does this by first taking a linear fit against the logarithmic x and y data. \n",
    "    This linear fit is then converted to the logarithmic function.\n",
    "\n",
    "    https://stackoverflow.com/a/30672483\n",
    "    \"\"\"\n",
    "\n",
    "    popt, pcov = scipy.optimize.curve_fit(linear_function, np.log10(values), np.log10(errors), p0=[1, -1])\n",
    "    a, b = popt[0], popt[1]\n",
    "\n",
    "    c = 10 ** b\n",
    "    return a, c\n",
    "\n",
    "\n",
    "def plot_error(values, errors, title=\"\", xlabel=\"\"):\n",
    "    \n",
    "    a, c = calc_error_fit(values, errors)\n",
    "\n",
    "    # Compute the fitted values back to expected values\n",
    "    y_fit_values = [exponential_function(value, a=a, c=c) for value in values]\n",
    "    \n",
    "    plt.plot(values, errors, label=\"data\")\n",
    "    plt.plot(values, y_fit_values, label=\"fit\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_error(i_values, i_errors, title=\"i error\", xlabel=\"i\")\n",
    "plot_error(s_values, s_errors, title=\"s error\", xlabel=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_j_dependance(i = 25, sample_method=\"pure\"):\n",
    "\n",
    "    s = get_s_with_comparable_error(i)\n",
    "    \n",
    "    area_differences = []\n",
    "    js = []\n",
    "    for j in range(1, i):\n",
    "        js.append(j)\n",
    "        area_differences.append(determine_area(i=j, s=s, sample_method=sample_method) - EXPECTED_AREA)\n",
    "\n",
    "    plt.plot(js, area_differences)\n",
    "    plt.ylabel(\"Area difference\")\n",
    "    plt.xlabel(\"j\")\n",
    "    plt.show()\n",
    "\n",
    "def get_s_with_comparable_error(i):\n",
    "    \"\"\"\n",
    "    Gets a s value, which has comparable error as the error in i.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtain the fit parameters from the error data in i and s\n",
    "    i_fit_values = calc_error_fit(i_values, i_errors)\n",
    "    s_fit_values = calc_error_fit(s_values, s_errors)\n",
    "\n",
    "    # Get the estimated i error\n",
    "    i_error = exponential_function(i, a=i_fit_values[0], c=i_fit_values[1])\n",
    "\n",
    "    # Calculate s from i error\n",
    "    s = inverse_exponential_function(i_error, a=s_fit_values[0], c=s_fit_values[1])\n",
    "\n",
    "    return int(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_j_dependance(i=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling method comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypercube vs pure: 0.026746542255364186\n",
      "orthogonal vs pure: 0.0252399990070164\n",
      "orthogonal vs hypercube: 0.676633145066146\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVRklEQVR4nO3df5RfdX3n8eeLcWwQyo808Tcm1uIayCqWkcoaK9HaQ7eoW0tX6GpLN6e0bDeKLWetZMsPe9Jd7Tlbt7CFwk7EHzDa+oOzelBxbQTGFdkJBkgIiFqorB6JEEOhRJP0vX98b3SS3MkMYb5zJzPPxzn3cOfzuff7fed+vnxf33s/3x+pKiRJ2tdhXRcgSZqdDAhJUisDQpLUyoCQJLUyICRJrZ7WdQHTadGiRbV06dKuy5CkQ8aGDRu+X1WL2/rmVEAsXbqUsbGxrsuQpENGkgcm6vMSkySplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVnPqg3KHsiTTcjv+voek6WJAzBKTPbEn8clf0ozyEpMkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJatW3gEiyLslDSTZN0H9aku1JNjbLRU37giS3JbkjyeYkl/arRknSxPr5m9TXAJcDHzrANrdU1Rn7tP0QeG1VPZZkEBhN8tmqurVPdUqSWvTtDKKqbgYeOYj9qqoea/4cbJaaztokSZPreg7i1OZS0meTnLinMclAko3AQ8AXquqrE91AknOTjCUZ27p16wyULEnzQ5cBcTuwpKpeBlwGXL+no6p2V9VJwPOBU5Isn+hGquqqqhqqqqHFixf3uWRJmj86C4iqenTPpaSqugEYTLJon21+AKwHTp/5CiVpfussIJI8O0ma9VOaWh5OsjjJMU374cDrgXu6qlOS5qu+vYspyQhwGrAoyYPAxfQmnKmqK4EzgfOS7AKeAM6qqkryHOCDSQbohcbfVNVn+lWnJKld3wKiqs6epP9yem+D3bf9TuDl/apLkjQ1Xb+LSZI0SxkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEFIfjYyMsHz5cgYGBli+fDkjIyNdlyRNWd9+clSa70ZGRlizZg3Dw8OsWLGC0dFRVq1aBcDZZx/wF3mlWcEzCKlP1q5dy/DwMCtXrmRwcJCVK1cyPDzM2rVruy5NmpJUVdc1TJuhoaEaGxvruoy+SMJcGqv5YGBggB07djA4OPjjtp07d7JgwQJ2797dYWXSTyTZUFVDbX2eQUh9smzZMkZHR/dqGx0dZdmyZR1VJD05BsQMWbhwIUkOegGe0v5JWLhwYcdHYX5Zs2YNq1atYv369ezcuZP169ezatUq1qxZ03Vp0pQ4ST1Dtm3b1vkloj1Bo5mxZyJ69erVbNmyhWXLlrF27VonqHXIcA5ihsyGOYTZUIOk2cU5CEnSk2ZASJJaGRCSpFYGhCSplQEhSWrVt4BIsi7JQ0k2TdB/WpLtSTY2y0VN+3FJ1ie5O8nmJO/oV42SpIn183MQ1wCXAx86wDa3VNUZ+7TtAv6oqm5P8tPAhiRfqKq7+1SnJKlF384gqupm4JGD2O+7VXV7s/6PwBbgedNcniRpEl3PQZya5I4kn01y4r6dSZYCLwe+OtENJDk3yViSsa1bt/axVEmaX7oMiNuBJVX1MuAy4PrxnUmOBD4BnF9Vj050I1V1VVUNVdXQ4sWL+1mvJM0rnQVEVT1aVY816zcAg0kWASQZpBcO11bVJ7uqUZLms84CIsmz03x7XJJTmloebtqGgS1V9d+6qk+S5ru+vYspyQhwGrAoyYPAxcAgQFVdCZwJnJdkF/AEcFZVVZIVwNuAu5JsbG7uwuYsQ5I0Q/oWEFV1wO80rqrL6b0Ndt/2UcDvpZakjnX9LiZJ0ixlQEiSWhkQkqRWBoQkqZUBIUlqZUBIklr189tcpXmj+cznU1JV01CJNH0MCGkaTPbknsQA0CHHS0ySpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlq5ecgZkhdfBRccnT3NUjSFBkQMySXPtr5B6WSUJd0WoKkQ4iXmCRJrQwISVIrA0KS1MqAkCS1MiAkSa2m/C6mJM8EFuz5u6r+oS8VSZJmhUnPIJK8Mcl9wN8DNwH3A5/tc12SpI5N5RLTnwKvBL5eVS8EXgfc2teqJEmdm0pA7Kyqh4HDkhxWVeuBoT7XJUnq2FTmIH6Q5EjgFuDaJA8Bj/e3LElS16ZyBvEm4J+A84HPAd8E3tDHmiRJs8CkZxBV9XiSJcDxVfXBJM8ABvpfmiT1X5JpuZ2uv2utH6byLqbfBT4O/HXT9Dzg+insty7JQ0k2TdB/WpLtSTY2y0VT3VeSpktVTbpMZbu5aCqXmP4AeBXwKEBV3Qc8cwr7XQOcPsk2t1TVSc3ynie5rySpj6YSED+sqh/t+SPJ04BJ47KqbgYeOZiinsq+0nRbuHAhSZ7SAjzl21i4cGHHR0LzzVTexXRTkguBw5O8HvgPwKen6f5PTXIH8B3ggqraPE23K02bbdu2zYpLCNN1rVyaqqmcQbwL2ArcBfwecAPwn6fhvm8HllTVy4DLmMK8Rpsk5yYZSzK2devWaShLkgSTnEEkGQA2V9VLgKun846r6tFx6zck+aski6rq+0/ydq4CrgIYGhrq/mWeJM0RBzyDqKrdwL1JXjDdd5zk2WnOmZOc0tTy8HTfj6T5bTbMIR2q80dTmYM4Ftic5DZ+8gnqqqo3HWinJCPAacCiJA8CFwODzc5XAmcC5yXZBTwBnFXNhd62fatq+En+2yRpVswhHarzR1MJiD8Ztx7g1cBZk+1UVWdP0n85cPnB7CtJ6r9JJ6mr6iZ6n4E4g97nE14LXNnfsiRJXZvwDCLJi4Gzm+X7wMeAVNXKGapNktShA11iuofeN7ieUVXfAEjyzhmpSpLUuQMFxJvpzTWsT/I54KP05iAk6ZBRFx8FlxzdfQ2HoAkDoqquB65PcgS9r/w+H3hmkiuAT1XVjTNSoSQ9Bbn00VnxLqa6pNMSDsqUvu4buA64LsmxwG/Q+3S1AaF5YTa8Av1xHTooXb/N9Nhjj+30/g9Wuk7W6TQ0NFRjY2Ndl9Gq6wco9B6kjzzidyA+WUk6fwU6m+qYj+bysU+yoapaf0Z6TgXEwiXL6vUXrtur7YyXPoe3nbqUJ360m3M+cNt++5x58vP5jaHjeOTxH3HeRzbs1//WVy7hDS97Lt/5wRO882Mb9+v/3Vf/LL90wrP45tbHuPCTd+3Xv/q1x7Pi+EVs/s523vPpu/fr/0+n/wtOXrKQDQ88wvs+d+9+/Re94QROfO7RHL70JN747iv26/+zN/9LXrT4SP733d/j6lu+tV//X7zlJJ57zOF8+o7v8JFbH9iv/4q3nszCI57O3459m49veHC//mt+5xQOf/oAH/7K/Xzmzu/u1/+x3zsVgKtu/iZf3PLQXn0LBgf44L8/BYC//OJ9fPkbe3+LyrHPeDpXvu1kAN77uXu4/YFte/U/5+gFvP+slwNw6ac3c/d3Ht2r/2cXH8F/efNLAXj3J+/kW1v3/iXcE557FBe/4UQAzv/o1/ju9h179f/8kmN51+kvAeD3P7yBbf/0o736X/Vzi3j7644nCb81/FV27Ny9V//rlj2Tc3/xRQC85a+/st+xme7H3k033cRrXvOaH/fP1GNv9L7vc9nf3bdf/3x67F0x8um9jv1MPfYAfnvdbX197P3MkT81YUBM5cv6JEnz0Jw6g5jNl5ieqrl8ijvbzZZjP1vqmI/m8rE/0CUmzyAkSa0MCElSq6l8WZ8kzVlTfYfhZNvNxUtQBoSkeW0uPrFPFy8xSZJaeQYhTcFs+aCjNJMMCGkS03EJYi6/TVJzl5eYJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmt+hYQSdYleSjJpgn6T0uyPcnGZrloXN/pSe5N8o0kf9yvGiVJE+vnGcQ1wOmTbHNLVZ3ULO8BSDIA/A/gV4ATgLOTnNDHOiVJLfoWEFV1M/DIQex6CvCNqvpWVf0I+CjwpmktTpI0qa7nIE5NckeSzyY5sWl7HvDtcds82LS1SnJukrEkY1u3bu1nrZI0r3QZELcDS6rqZcBlwPUHcyNVdVVVDVXV0OLFi6ezPkma1zoLiKp6tKoea9ZvAAaTLAL+H3DcuE2f37RJkmZQZ79JneTZwPeqqpKcQi+sHgZ+AByf5IX0guEs4De7qlOaiiRPeRt/s1qzTd8CIskIcBqwKMmDwMXAIEBVXQmcCZyXZBfwBHBW9f4P2ZXkPwKfBwaAdVW1uV91StPBJ3fNRZlLD+yhoaEaGxvruoy+SOKTkKRpl2RDVQ219XX9LiZJ0ixlQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEFIfjYyMsHz5cgYGBli+fDkjIyNdlyRN2dO6LkCaq0ZGRlizZg3Dw8OsWLGC0dFRVq1aBcDZZ5/dcXXS5DyDkPpk7dq1DA8Ps3LlSgYHB1m5ciXDw8OsXbu269KkKUlVdV3DtBkaGqqxsbGuy+iLJMylsZoPBgYG2LFjB4ODgz9u27lzJwsWLGD37t0dVib9RJINVTXU1ucZhNQny5YtY3R0dK+20dFRli1b1lFF0pNjQEh9smbNGlatWsX69evZuXMn69evZ9WqVaxZs6br0qQpcZJa6pM9E9GrV69my5YtLFu2jLVr1zpBrUOGcxCHCOcgJPWDcxCSpCfNgJAktTIgJEmtDAhJUqu+BUSSdUkeSrJpku1ekWRXkjPHtb03yaZmeUu/apQkTayfZxDXAKcfaIMkA8B7gRvHtf0q8PPAScAvABckOapvVUqSWvUtIKrqZuCRSTZbDXwCeGhc2wnAzVW1q6oeB+5kkqCRJE2/zuYgkjwP+DXgin267gBOT/KMJIuAlcBxB7idc5OMJRnbunVr/wqWpHmmy0nq9wPvqqp/Ht9YVTcCNwD/BxgBvgJM+M1mVXVVVQ1V1dDixYv7WK4kzS9dftXGEPDRJACLgH+dZFdVXV9Va4G1AEmuA77eXZmSND91FhBV9cI960muAT5TVdc3E9fHVNXDSV4KvJRxk9iSpJnRt4BIMgKcBixK8iBwMTAIUFVXHmDXQeCW5sziUeCtVbWrX3VKktr1LSCqaspfWVlV54xb30HvnUySpA75SWpJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUqstflNM4ze9fPOVtqmo6ypEkA2K28Ild0mzjJSZJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0ylz6glWQr8EDXdfTJIuD7XRehg+b4Hdrm8vgtqarFbR1zKiDmsiRjVTXUdR06OI7foW2+jp+XmCRJrQwISVIrA+LQcVXXBegpcfwObfNy/JyDkCS18gxCktTKgJAktTIgNK8lWZpkU9d1TCTJl5LMu7dXTqckF45bn5XjPVvH2YA4hCXxFwEPIY7XzErPYcCFk26sVgZEx5pXNPckuTbJliQfT/KMJPcnWdRsM5TkS836JUk+nOTLwIeTLE7yiST/t1le1eW/5xA1kOTqJJuT3JjkxCS37+lMcvyev5txeV+Su5LcluTnmvbWcWgZr2cl+VSSO5rlX+37qjbJBUkuGVff25JsTLIpySnNNkckWdfU8LUkb5qB4zTrJPnD5rhsSnJ+cyzvTfIhYBMwDBzeHL9rm932He/Dm9s6KcmtSe5sxujYpv0VTdvGJH++Z6ySLEjygeax8LUkK5v2c5J8MsnnktyX5H3j6r0iyVhz35fO5LE6KFXl0uECLAUKeFXz9zrgAuB+YFHTNgR8qVm/BNgAHN78fR2woll/AbCl63/TobQ0x38XcFLz998AbwXWj2v7M2B1s34/sKZZ/y3gMwcah5bx+hhwfrM+ABzd1LBpXE0XAJc0618Crm7Wf3HPdk1Nb23WjwG+DhzR9fGc4bE7GbgLOAI4EtgMvBz4Z+CV47Z7bLLxbtbvBF7TrL8HeH+zvgk4tVn/r+PG4I+Adc36S4B/ABYA5wDfasZ2Ab2v/zmu2W7huLH/EvDSceM81PUx3XfxlHd2+HZVfblZ/wjw9km2/19V9USz/kvACUn29B2V5MiqeqwPdc5Vf19VG5v1DfSeRP4n8DtJ/hB4C3DKuO1Hxv33L5r11nFo1seP12vpBQtVtRvYvueV6gGMNNvfnOSoJMcAvwy8MckFzTYLaIJpKv/gOWIF8KmqehwgySeBVwMPVNWtB9hvv/FOcjRwTFXd1LR/EPjb5lj/dFV9pWm/Djhj3P1fBlBV9yR5AHhx0/fFqtre1HU3sAT4NvBvk5wLPA14DnACvWCalQyI2WHfD6MUvVc5ey4BLtin//Fx64fRe7W0o0+1zQc/HLe+Gzgc+ARwMfB3wIaqenjcNtWy3joOTWCMH68248ca9h/vtsdHgF+vqnsnue35aLLj3Tbe023f+3hakhfSOzt8RVVtS3IN+4/1rOIcxOzwgiSnNuu/CYzSu5RxctP26wfY90Zg9Z4/kpzUh/rmneaJ/vPAFcAH9ul+y7j/7nllOdVx+CJwXrPNQPPK9XvAM5P8TJKf4ievUPe6vyQrgO3NK9PPA6vTJFCSlz/Zf+MccAvwb5o5uyOAX2va9rUzyeCBbqg5ptuSvLppehtwU1X9APjHJL/QtJ+1z/3/O4AkL6Z3BnegwD6KXnhtT/Is4FcOVNNsYEDMDvcCf5BkC3AsvSelS4H/nmSM3iuQibwdGGom0e4Gfr/v1c4f19K7nn3jPu3HJrkTeAfwzqZtquPwDmBlkrvoXd44oap20rvmfRvwBeCeffbZkeRrwJXAqqbtT4FB4M4km5u/55Wquh24ht5x+yq9y4LbWja9it5xuralb7zfBv68GduT6I0J9I751Uk20pvv2N60/xVwWDOWHwPOqaofMoGqugP4Gr3xvQ748kTbzhZ+1UbHkiylN9G5vOtatLfm+v7RVfUn49rupzeZOFd/G0D7GD+nl+SPgedU1Ts6LmtGOAchtUjyKeBF9CaVNb/9apJ303u+fIDeu5TmBc8gJEmtnIOQJLUyICRJrQwISVIrA0KS1MqAkCS1+v/2wyWAIXmwLwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_boxplot_data(s=10000, i=1000, nruns=10):\n",
    "\n",
    "    pures = []\n",
    "    hypercubes = []\n",
    "    orthogonals = []\n",
    "\n",
    "    for _ in range(nruns):\n",
    "\n",
    "        pures.append(determine_area(s=s, i=i, sample_method=\"pure\"))\n",
    "        hypercubes.append(determine_area(s=s, i=i, sample_method=\"hypercube\"))\n",
    "        orthogonals.append(determine_area(s=s, i=i, sample_method=\"orthogonal\"))\n",
    "\n",
    "    return [pures, hypercubes, orthogonals]\n",
    "\n",
    "def plot_sampling_comparison(data_entries, labels):\n",
    "\n",
    "    plt.boxplot(data_entries, labels=labels)\n",
    "    plt.axhline(EXPECTED_AREA, linestyle=\"--\")\n",
    "\n",
    "    plt.ylabel(\"Area\")\n",
    "    plt.show()\n",
    "\n",
    "def print_p_values(data_entries, labels):\n",
    "    \"\"\"\n",
    "    Gets a pvalue for each data-entry against the others and prints these results.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(data_entries)):\n",
    "        for j in range(i):\n",
    "\n",
    "            data1 = data_entries[i]\n",
    "            data2 = data_entries[j]\n",
    "\n",
    "            pvalue = get_pvalue(data1, data2)\n",
    "\n",
    "            print(f\"{labels[i]} vs {labels[j]}: {pvalue}\")\n",
    "    \n",
    "\n",
    "def get_pvalue(data1, data2):\n",
    "    \"\"\"Calculates the pvalue for two data sets. \"\"\"\n",
    "\n",
    "    return stats.ttest_ind(data1, data2).pvalue\n",
    "\n",
    "data_entries = get_boxplot_data(s=100000, i=1000, nruns=25)\n",
    "labels = [\"pure\", \"hypercube\", \"orthogonal\"]\n",
    "\n",
    "print_p_values(data_entries, labels)\n",
    "plot_sampling_comparison(data_entries, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quad tree sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box():\n",
    "\n",
    "    def __init__(self, xmin, xmax, ymin, ymax):\n",
    "\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.ymin = ymin\n",
    "        self.ymax = ymax\n",
    "\n",
    "    def calc_area(self):\n",
    "\n",
    "        return (self.xmax - self.xmin) * (self.ymax - self.ymin)\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        return f\"{self.xmin}, {self.xmax}, {self.ymin}, {self.ymax}\"\n",
    "\n",
    "def subdivide_box(box):\n",
    "\n",
    "    xcenter = (box.xmax + box.xmin) / 2\n",
    "    ycenter = (box.ymax + box.ymin) / 2\n",
    "\n",
    "    box1 = Box(box.xmin, xcenter, box.ymin, ycenter)\n",
    "    box2 = Box(xcenter, box.xmax, box.ymin, ycenter)\n",
    "    box3 = Box(box.xmin, xcenter, ycenter, box.ymax)\n",
    "    box4 = Box(xcenter, box.xmax, ycenter, box.ymax)\n",
    "\n",
    "    return (box1, box2, box3, box4)\n",
    "\n",
    "def quad_tree_area(box, box_area_treshold=0.001, s=100, i=10000):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    area: The mandelbrot area inside the box.\n",
    "    evals: The number of box evaulations performed to obtain this area.\n",
    "    \"\"\"\n",
    "\n",
    "    if box.calc_area() < box_area_treshold:\n",
    "        return determine_area(s=s, i=i, xmin=box.xmin, xmax=box.xmax, ymin=box.ymin, ymax=box.ymax, sample_method=\"pure\"), 1\n",
    "\n",
    "    Z0 = generate_sample_points_pure_random(s, box.xmin, box.xmax, box.ymin, box.ymax)\n",
    "\n",
    "    Z = Z0\n",
    "\n",
    "    for _ in range(i):\n",
    "\n",
    "        Z = np.where(abs(Z) < 2, Z ** 2 + Z0, 100)\n",
    "        \n",
    "        # If all points diverge return 0\n",
    "        if (np.abs(Z) > 2).all():\n",
    "            return 0, 1\n",
    "\n",
    "    # if all points points still havent diverged return area of box\n",
    "    if(np.abs(Z) <  2).all():\n",
    "        return box.calc_area(), 1\n",
    "\n",
    "    # At this point in the code the box contains both converge and diverge points.\n",
    "    # The box is subdived box in 4 smaller boxs from which the area is calculated.\n",
    "\n",
    "    boxs = subdivide_box(box)\n",
    "    area = 0\n",
    "    evals = 0\n",
    "    for b in boxs:\n",
    "        results = quad_tree_area(b, box_area_treshold=box_area_treshold, s=s, i=i)\n",
    "        area += results[0]\n",
    "        evals += results[1]\n",
    "\n",
    "    return area, evals\n",
    "\n",
    "area, evals = quad_tree_area(Box(-2, 2, -2, 2))\n",
    "print(area, evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
